import 'dart:io';
import 'dart:convert';
import 'package:flutter/foundation.dart';
import 'package:http/http.dart' as http;
import 'package:mathquest/features/resources/arxiv_service.dart';

class OllamaService {
  static const String _baseUrl = 'http://localhost:11434';
  static const String _apiUrl = '$_baseUrl/api';

  /// Verifica se o Ollama est√° instalado e rodando
  Future<bool> isOllamaRunning() async {
    try {
      final response = await http.get(
        Uri.parse('$_baseUrl/api/tags'),
        headers: {'Content-Type': 'application/json'},
      ).timeout(const Duration(seconds: 5));

      return response.statusCode == 200;
    } catch (e) {
      return false;
    }
  }

  /// Verifica se o Ollama est√° instalado (mas pode n√£o estar rodando)
  Future<bool> isOllamaInstalled() async {
    try {
      // Primeiro tenta o comando direto
      final result = await Process.run('ollama', ['--version']);
      return result.exitCode == 0;
    } catch (e) {
      // Se falhou, tenta caminhos comuns do Windows
      final commonPaths = [
        r'C:\Users\' +
            Platform.environment['USERNAME']! +
            r'\AppData\Local\Programs\Ollama\ollama.exe',
        r'C:\Program Files\Ollama\ollama.exe',
        r'C:\Program Files (x86)\Ollama\ollama.exe',
      ];

      for (final path in commonPaths) {
        try {
          final result = await Process.run(path, ['--version']);
          if (result.exitCode == 0) {
            if (kDebugMode) {
              print('‚úÖ Ollama encontrado em: $path');
            }
            return true;
          }
        } catch (e) {
          // Continua para o pr√≥ximo caminho
        }
      }

      return false;
    }
  }

  /// Instala o Ollama usando winget
  Future<bool> installOllama() async {
    try {
      if (kDebugMode) {
        print('üîß Instalando Ollama via winget...');
      }

      // Verifica se winget est√° dispon√≠vel
      final wingetCheck = await Process.run('winget', ['--version']);
      if (wingetCheck.exitCode != 0) {
        if (kDebugMode) {
          print('‚ùå winget n√£o est√° dispon√≠vel');
        }
        return false;
      }

      // Instala o Ollama
      final result = await Process.run('winget', ['install', 'Ollama.Ollama']);

      if (result.exitCode == 0) {
        if (kDebugMode) {
          print('‚úÖ Ollama instalado com sucesso!');
        }

        // Aguarda um pouco para a instala√ß√£o finalizar
        await Future.delayed(const Duration(seconds: 3));

        // Inicia o servi√ßo do Ollama
        await startOllamaService();

        return true;
      } else {
        if (kDebugMode) {
          print('‚ùå Erro ao instalar Ollama: ${result.stderr}');
        }
        return false;
      }
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Erro durante instala√ß√£o: $e');
      }
      return false;
    }
  }

  /// Inicia o servi√ßo do Ollama
  Future<bool> startOllamaService() async {
    try {
      if (kDebugMode) {
        print('üöÄ Iniciando servi√ßo Ollama...');
      }

      // Encontra o caminho do Ollama
      final ollamaPath = await getOllamaPath();
      if (ollamaPath == null) {
        if (kDebugMode) {
          print('‚ùå Ollama n√£o encontrado no sistema');
        }
        return false;
      }

      // Tenta iniciar o Ollama em background
      Process.start(ollamaPath, ['serve'], runInShell: true);

      // Aguarda o servi√ßo iniciar
      await Future.delayed(const Duration(seconds: 5));

      // Verifica se est√° rodando
      final isRunning = await isOllamaRunning();
      if (isRunning) {
        if (kDebugMode) {
          print('‚úÖ Ollama est√° rodando!');
        }
        return true;
      } else {
        if (kDebugMode) {
          print('‚ö†Ô∏è Ollama pode estar iniciando... aguarde alguns segundos');
        }
        return false;
      }
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Erro ao iniciar Ollama: $e');
      }
      return false;
    }
  }

  /// Detecta a quantidade de RAM do sistema
  Future<int> getSystemRAM() async {
    ProcessResult? result;
    try {
      // Usa PowerShell para obter informa√ß√µes de RAM
      result = await Process.run('powershell', [
        '-Command',
        '(Get-CimInstance -ClassName Win32_ComputerSystem).TotalPhysicalMemory / 1GB'
      ]);

      if (result.exitCode == 0) {
        String ramString = result.stdout.toString().trim();
        // Substitui v√≠rgula por ponto para resolver problemas de locale
        ramString = ramString.replaceAll(',', '.');
        final ramGB = double.parse(ramString);
        return ramGB.round();
      }
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Erro ao detectar RAM: $e');
        print('RAM output: ${result?.stdout}');
      }
    }

    // Valor padr√£o se n√£o conseguir detectar
    return 8;
  }

  /// Detecta se o sistema tem GPU dedicada adequada para IA
  Future<bool> hasAICapableGPU() async {
    try {
      final result = await Process.run('powershell', [
        '-Command',
        r'Get-CimInstance -ClassName Win32_VideoController | Where-Object {$_.AdapterRAM -gt 2000000000 -and $_.Name -notlike "*Basic*" -and $_.Name -notlike "*Microsoft*"} | Select-Object Name, AdapterRAM'
      ]);

      if (result.exitCode == 0) {
        final output = result.stdout.toString();
        // Verifica se h√° alguma GPU com mais de 2GB de VRAM
        if (output.contains('AdapterRAM') && output.trim().isNotEmpty) {
          if (kDebugMode) {
            print('‚úÖ GPU dedicada detectada para IA');
            print('GPU info: ${output.trim()}');
          }
          return true;
        }
      }
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Erro ao detectar GPU: $e');
      }
    }

    if (kDebugMode) {
      print('‚ö†Ô∏è Nenhuma GPU dedicada adequada detectada');
    }
    return false;
  }

  /// Sugere o melhor modelo baseado na RAM dispon√≠vel e presen√ßa de GPU
  Future<String> getRecommendedModel(int ramGB) async {
    final hasGPU = await hasAICapableGPU();

    if (!hasGPU) {
      // Sem GPU dedicada: usa modelos menores e mais conservadores
      if (kDebugMode) {
        print(
            'üîß Sistema sem GPU dedicada - recomendando modelos otimizados para CPU');
      }

      if (ramGB >= 16) {
        return 'llama3.2:3b'; // Modelo pequeno mesmo com muita RAM
      } else if (ramGB >= 8) {
        return 'llama3.2:1b'; // Modelo muito pequeno para CPU
      } else {
        return 'gemma2:2b'; // Modelo ultra-leve para sistemas limitados
      }
    } else {
      // Com GPU dedicada: pode usar modelos maiores
      if (kDebugMode) {
        print('üöÄ GPU dedicada detectada - recomendando modelos otimizados');
      }

      if (ramGB >= 32) {
        return 'llama3.1:70b'; // Modelo grande para sistemas com muita RAM + GPU
      } else if (ramGB >= 16) {
        return 'llama3.1:13b'; // Modelo m√©dio para sistemas com RAM moderada + GPU
      } else if (ramGB >= 8) {
        return 'llama3.1:8b'; // Modelo padr√£o para 8GB+ com GPU
      } else {
        return 'llama3.2:3b'; // Modelo pequeno para sistemas com pouca RAM mas com GPU
      }
    }
  }

  /// Vers√£o s√≠ncrona para compatibilidade (usa valores padr√£o conservadores)
  String getRecommendedModelSync(int ramGB, {bool hasGPU = false}) {
    if (!hasGPU) {
      // Sem GPU dedicada: usa modelos menores e mais conservadores
      if (ramGB >= 16) {
        return 'llama3.2:3b'; // Modelo pequeno mesmo com muita RAM
      } else if (ramGB >= 8) {
        return 'llama3.2:1b'; // Modelo muito pequeno para CPU
      } else {
        return 'gemma2:2b'; // Modelo ultra-leve para sistemas limitados
      }
    } else {
      // Com GPU dedicada: pode usar modelos maiores
      if (ramGB >= 32) {
        return 'llama3.1:70b'; // Modelo grande para sistemas com muita RAM + GPU
      } else if (ramGB >= 16) {
        return 'llama3.1:13b'; // Modelo m√©dio para sistemas com RAM moderada + GPU
      } else if (ramGB >= 8) {
        return 'llama3.1:8b'; // Modelo padr√£o para 8GB+ com GPU
      } else {
        return 'llama3.2:3b'; // Modelo pequeno para sistemas com pouca RAM mas com GPU
      }
    }
  }

  /// Lista modelos instalados
  Future<List<String>> getInstalledModels() async {
    try {
      final response = await http.get(
        Uri.parse('$_apiUrl/tags'),
        headers: {'Content-Type': 'application/json'},
      ).timeout(const Duration(seconds: 10));

      if (response.statusCode == 200) {
        final data = json.decode(response.body);
        final models = data['models'] as List;
        return models.map((model) => model['name'] as String).toList();
      }
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Erro ao listar modelos: $e');
      }
    }

    return [];
  }

  /// Encontra o caminho do execut√°vel Ollama
  Future<String?> getOllamaPath() async {
    try {
      // Primeiro tenta o comando direto
      final result = await Process.run('ollama', ['--version']);
      if (result.exitCode == 0) {
        return 'ollama';
      }
    } catch (e) {
      // Se falhou, tenta caminhos comuns do Windows
      final commonPaths = [
        r'C:\Users\' +
            Platform.environment['USERNAME']! +
            r'\AppData\Local\Programs\Ollama\ollama.exe',
        r'C:\Program Files\Ollama\ollama.exe',
        r'C:\Program Files (x86)\Ollama\ollama.exe',
      ];

      for (final path in commonPaths) {
        try {
          final result = await Process.run(path, ['--version']);
          if (result.exitCode == 0) {
            return path;
          }
        } catch (e) {
          // Continua para o pr√≥ximo caminho
        }
      }
    }

    return null;
  }

  /// Baixa e instala um modelo
  Future<bool> pullModel(String modelName) async {
    try {
      if (kDebugMode) {
        print('üì• Baixando modelo $modelName...');
      }
      if (kDebugMode) {
        print('‚è≥ Isso pode levar alguns minutos dependendo da sua conex√£o');
      }

      // Encontra o caminho do Ollama
      final ollamaPath = await getOllamaPath();
      if (ollamaPath == null) {
        if (kDebugMode) {
          print('‚ùå Ollama n√£o encontrado no sistema');
        }
        return false;
      }

      final result = await Process.run(ollamaPath, ['pull', modelName]);

      if (result.exitCode == 0) {
        if (kDebugMode) {
          print('‚úÖ Modelo $modelName baixado com sucesso!');
        }
        return true;
      } else {
        if (kDebugMode) {
          print('‚ùå Erro ao baixar modelo: ${result.stderr}');
        }
        return false;
      }
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Erro durante download: $e');
      }
      return false;
    }
  }

  /// Configura√ß√£o completa: instala Ollama e modelo recomendado
  Future<bool> setupOllama() async {
    try {
      if (kDebugMode) {
        print('üîç Verificando instala√ß√£o do Ollama...');
      }

      // 1. Verifica se est√° rodando
      bool isRunning = await isOllamaRunning();

      if (!isRunning) {
        // 2. Verifica se est√° instalado
        bool isInstalled = await isOllamaInstalled();

        if (!isInstalled) {
          // 3. Instala se necess√°rio
          if (kDebugMode) {
            print('üì¶ Ollama n√£o encontrado. Instalando...');
          }
          bool installed = await installOllama();
          if (!installed) {
            return false;
          }
        } else {
          // 4. Apenas inicia o servi√ßo
          await startOllamaService();
        }

        // Aguarda inicializa√ß√£o
        await Future.delayed(const Duration(seconds: 5));
      }

      // 5. Detecta RAM e sugere modelo
      final ramGB = await getSystemRAM();
      final recommendedModel = await getRecommendedModel(ramGB);

      if (kDebugMode) {
        print('üíæ RAM detectada: ${ramGB}GB');
      }
      if (kDebugMode) {
        print('ü§ñ Modelo recomendado: $recommendedModel');
      }

      // 6. Verifica modelos instalados
      final installedModels = await getInstalledModels();

      if (!installedModels.contains(recommendedModel)) {
        if (kDebugMode) {
          print('üì• Instalando modelo recomendado...');
        }
        final modelInstalled = await pullModel(recommendedModel);
        if (!modelInstalled) {
          if (kDebugMode) {
            print('‚ö†Ô∏è N√£o foi poss√≠vel instalar o modelo automaticamente.');
            print('üí° Instale o Ollama manualmente:');
            print('   1. Baixe de: https://ollama.ai');
            print('   2. Execute: ollama pull $recommendedModel');
          }
          return false;
        }
      } else {
        if (kDebugMode) {
          print('‚úÖ Modelo $recommendedModel j√° est√° instalado!');
        }
      }

      return true;
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Erro na configura√ß√£o: $e');
      }
      return false;
    }
  }

  /// Gera resumo usando Ollama
  Future<String> generateSummary(String text, {String? model}) async {
    try {
      // Usa modelo padr√£o se n√£o especificado
      if (model == null) {
        final ramGB = await getSystemRAM();
        model = await getRecommendedModel(ramGB);
      }

      final prompt = '''
Analise o seguinte texto cient√≠fico e crie um resumo estruturado seguindo este formato:

**OBJETIVO:** [Principal objetivo ou problema abordado]
**M√âTODO:** [Metodologia ou abordagem utilizada]
**RESULTADOS:** [Principais descobertas ou resultados]
**IMPLICA√á√ïES:** [Import√¢ncia e implica√ß√µes dos resultados]

Texto para an√°lise:
$text

Responda em portugu√™s e seja conciso mas informativo.
''';

      final response = await http
          .post(
            Uri.parse('$_apiUrl/generate'),
            headers: {'Content-Type': 'application/json'},
            body: json.encode({
              'model': model,
              'prompt': prompt,
              'stream': false,
            }),
          )
          .timeout(const Duration(minutes: 2));

      if (response.statusCode == 200) {
        final data = json.decode(response.body);
        return data['response'] as String;
      } else {
        throw Exception('Erro HTTP ${response.statusCode}');
      }
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Erro ao gerar resumo: $e');
      }
      return 'Erro ao processar o texto com Ollama';
    }
  }

  /// Gera estado da arte baseado em m√∫ltiplos artigos
  Future<String> generateStateOfArt(List<String> articles, String topic) async {
    try {
      final ramGB = await getSystemRAM();
      final model = await getRecommendedModel(ramGB);

      final combinedText = articles.join('\n\n---\n\n');

      final prompt = '''
Com base nos seguintes artigos cient√≠ficos sobre "$topic", crie um estado da arte seguindo rigorosamente esta estrutura acad√™mica em formato LaTeX:

\\section{Introdu√ß√£o}
Apresente uma vis√£o geral do tema de estudo, destacando sua import√¢ncia e a necessidade de investigar o est√°gio atual da pesquisa.

\\section{Crit√©rios de Sele√ß√£o dos Estudos}
Descreva que foram analisados ${articles.length} estudos relevantes obtidos na base arXiv, selecionados por relev√¢ncia ao tema "$topic".

\\section{Principais Temas e Abordagens}
Agrupe a literatura em categorias, t√≥picos ou metodologias relevantes, indicando o foco principal de cada grupo. Para cada tema identificado, cite os estudos espec√≠ficos.

\\section{Contribui√ß√µes Relevantes}
Apresente as principais descobertas, avan√ßos ou propostas dos estudos revisados, evidenciando sua contribui√ß√£o para o tema. Cite trabalhos espec√≠ficos e suas contribui√ß√µes.

\\section{Lacunas e Desafios}
Discuta as limita√ß√µes, dificuldades e √°reas pouco exploradas identificadas na literatura analisada.

\\section{Considera√ß√µes Finais}
Fa√ßa um resumo dos pontos principais identificados e destaque as dire√ß√µes futuras de pesquisa no tema.

---

ARTIGOS PARA AN√ÅLISE:
$combinedText

INSTRU√á√ïES IMPORTANTES:
- Gere APENAS conte√∫do LaTeX v√°lido (sem cabe√ßalho \\documentclass ou \\begin{document})
- Use comandos LaTeX adequados: \\section{}, \\subsection{}, \\textbf{}, \\textit{}, \\cite{}
- Para listas use \\begin{itemize} \\item ... \\end{itemize}
- Para cita√ß√µes use \\textit{NomeDoArtigo} ou refer√™ncias diretas
- Use linguagem acad√™mica rigorosa
- Cite trabalhos espec√≠ficos quando relevante
- Seja detalhado e anal√≠tico
- Escreva em portugu√™s brasileiro
- N√ÉO use caracteres especiais sem escape (%, &, #, _, ^, {, }, ~, \\)
''';

      final response = await http
          .post(
            Uri.parse('$_apiUrl/generate'),
            headers: {'Content-Type': 'application/json'},
            body: json.encode({
              'model': model,
              'prompt': prompt,
              'stream': false,
            }),
          )
          .timeout(const Duration(minutes: 5));

      if (response.statusCode == 200) {
        final data = json.decode(response.body);
        return data['response'] as String;
      } else {
        throw Exception('Erro HTTP ${response.statusCode}');
      }
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Erro ao gerar estado da arte: $e');
      }
      return 'Erro ao processar os artigos com Ollama';
    }
  }

  /// Gera estado da arte com streaming token por token
  Stream<String> generateStateOfArtStreaming(
      List<String> articles, String topic) async* {
    try {
      final ramGB = await getSystemRAM();
      final model = await getRecommendedModel(ramGB);

      final combinedText = articles.join('\n\n---\n\n');

      final prompt = '''
Com base nos seguintes artigos cient√≠ficos sobre "$topic", crie um estado da arte seguindo rigorosamente esta estrutura acad√™mica em formato LaTeX:

\\section{Introdu√ß√£o}
Apresente uma vis√£o geral do tema de estudo, destacando sua import√¢ncia e a necessidade de investigar o est√°gio atual da pesquisa.

\\section{Crit√©rios de Sele√ß√£o dos Estudos}
Descreva que foram analisados ${articles.length} estudos relevantes obtidos na base arXiv, selecionados por relev√¢ncia ao tema "$topic".

\\section{Principais Temas e Abordagens}
Agrupe a literatura em categorias, t√≥picos ou metodologias relevantes, indicando o foco principal de cada grupo. Para cada tema identificado, cite os estudos espec√≠ficos.

\\section{Contribui√ß√µes Relevantes}
Apresente as principais descobertas, avan√ßos ou propostas dos estudos revisados, evidenciando sua contribui√ß√£o para o tema. Cite trabalhos espec√≠ficos e suas contribui√ß√µes.

\\section{Lacunas e Desafios}
Discuta as limita√ß√µes, dificuldades e √°reas pouco exploradas identificadas na literatura analisada.

\\section{Considera√ß√µes Finais}
Fa√ßa um resumo dos pontos principais identificados e destaque as dire√ß√µes futuras de pesquisa no tema.

---

ARTIGOS PARA AN√ÅLISE:
$combinedText

INSTRU√á√ïES IMPORTANTES:
- Gere APENAS conte√∫do LaTeX v√°lido (sem cabe√ßalho \\documentclass ou \\begin{document})
- Use comandos LaTeX adequados: \\section{}, \\subsection{}, \\textbf{}, \\textit{}, \\cite{}
- Para listas use \\begin{itemize} \\item ... \\end{itemize}
- Para cita√ß√µes use \\textit{NomeDoArtigo} ou refer√™ncias diretas
- Use linguagem acad√™mica rigorosa
- Cite trabalhos espec√≠ficos quando relevante
- Seja detalhado e anal√≠tico
- Escreva em portugu√™s brasileiro
- N√ÉO use caracteres especiais sem escape (%, &, #, _, ^, {, }, ~, \\)
''';

      final request = http.Request('POST', Uri.parse('$_apiUrl/generate'));
      request.headers['Content-Type'] = 'application/json';
      request.body = json.encode({
        'model': model,
        'prompt': prompt,
        'stream': true, // Habilita streaming
      });

      final streamedResponse = await request.send();

      if (streamedResponse.statusCode == 200) {
        await for (final chunk
            in streamedResponse.stream.transform(utf8.decoder)) {
          // Cada chunk pode conter m√∫ltiplas linhas JSON
          final lines =
              chunk.split('\n').where((line) => line.trim().isNotEmpty);

          for (final line in lines) {
            try {
              final data = json.decode(line);
              if (data['response'] != null) {
                yield data['response'] as String;
              }

              // Verifica se a gera√ß√£o terminou
              if (data['done'] == true) {
                return;
              }
            } catch (e) {
              // Ignora linhas JSON inv√°lidas
              if (kDebugMode) {
                print('Linha JSON inv√°lida ignorada: $line');
              }
            }
          }
        }
      } else {
        yield 'Erro HTTP ${streamedResponse.statusCode}';
      }
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Erro ao gerar estado da arte com streaming: $e');
      }
      yield 'Erro ao processar os artigos com Ollama: $e';
    }
  }

  /// Baixa PDF do arXiv
  Future<Uint8List?> downloadPDF(String pdfUrl) async {
    try {
      if (kDebugMode) {
        print('üì• Baixando PDF: $pdfUrl');
      }

      final response = await http.get(
        Uri.parse(pdfUrl),
        headers: {'User-Agent': 'MathStateArt/1.0'},
      ).timeout(const Duration(minutes: 2));

      if (response.statusCode == 200) {
        if (kDebugMode) {
          print(
              '‚úÖ PDF baixado com sucesso (${response.bodyBytes.length} bytes)');
        }
        return response.bodyBytes;
      } else {
        throw Exception('Erro HTTP ${response.statusCode}');
      }
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Erro ao baixar PDF: $e');
      }
      return null;
    }
  }

  /// Extrai texto de PDF usando abordagem h√≠brida
  Future<String> extractTextFromPDF(String pdfUrl) async {
    try {
      if (kDebugMode) {
        print('üìÑ Tentando extrair texto do PDF...');
      }

      // Primeiro, tenta baixar o PDF
      final pdfBytes = await downloadPDF(pdfUrl);
      if (pdfBytes == null) {
        return 'Erro ao baixar o PDF';
      }

      // Para esta vers√£o, vamos simular a extra√ß√£o de texto
      // Em uma implementa√ß√£o completa, voc√™ usaria uma biblioteca como syncfusion_flutter_pdf
      if (kDebugMode) {
        print('‚ö†Ô∏è Extra√ß√£o de PDF n√£o implementada nesta vers√£o');
      }
      if (kDebugMode) {
        print('üìù Usando abstract como fallback...');
      }

      return 'PDF baixado com sucesso (${pdfBytes.length} bytes), mas extra√ß√£o de texto n√£o implementada nesta vers√£o.';
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Erro ao processar PDF: $e');
      }
      return 'Erro na extra√ß√£o do PDF: ${e.toString()}';
    }
  }

  /// Processa artigo: baixa PDF, extrai texto e gera resumo
  Future<String> processArticle(ArxivArticle article) async {
    try {
      if (kDebugMode) {
        print('üîÑ Processando artigo: ${article.title}');
      }

      // Tenta extrair texto do PDF
      String content = await extractTextFromPDF(article.link);

      // Se a extra√ß√£o falhou, usa apenas o abstract
      if (content.startsWith('Erro') || content.length < 100) {
        if (kDebugMode) {
          print('‚ö†Ô∏è Falha na extra√ß√£o do PDF, usando abstract...');
        }
        content =
            '${article.title}\n\nAutores: ${article.authors}\n\nResumo: ${article.summary}';
      }

      // Gera resumo estruturado
      final summary = await generateSummary(content);

      return '''
**ARTIGO:** ${article.title}
**AUTORES:** ${article.authors}
**DATA:** ${article.published.year}-${article.published.month.toString().padLeft(2, '0')}-${article.published.day.toString().padLeft(2, '0')}
**CATEGORIAS:** ${article.categories.join(', ')}
**LINK:** ${article.link}

$summary

---
''';
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Erro ao processar artigo: $e');
      }
      return '''
**ARTIGO:** ${article.title}
**ERRO:** N√£o foi poss√≠vel processar este artigo completamente.
**RESUMO B√ÅSICO:** ${article.summary}

---
''';
    }
  }

  /// Gera estado da arte completo com processamento de PDFs
  Future<String> generateCompleteStateOfArt(
    List<ArxivArticle> articles,
    String topic, {
    Function(String)? onProgress,
  }) async {
    try {
      onProgress?.call('üöÄ Iniciando gera√ß√£o de estado da arte com IA...');
      if (kDebugMode) {
        print('üöÄ Iniciando gera√ß√£o de estado da arte com IA...');
      }
      onProgress?.call('üìä Processando ${articles.length} artigos');
      if (kDebugMode) {
        print('üìä Processando ${articles.length} artigos');
      }

      // Configura Ollama se necess√°rio
      onProgress?.call('üîß Configurando Ollama...');
      await setupOllama();

      List<String> processedArticles = [];
      int successCount = 0;

      // Primeiro, baixa todos os PDFs
      onProgress?.call('üì• Baixando todos os PDFs...');
      Map<String, String> pdfContents = {};

      for (int i = 0; i < articles.length; i++) {
        final article = articles[i];
        final titlePreview = article.title.length > 40
            ? '${article.title.substring(0, 40)}...'
            : article.title;

        onProgress?.call(
            'üìÑ Baixando PDF ${i + 1}/${articles.length}: $titlePreview');

        try {
          final content = await extractTextFromPDF(article.link);
          pdfContents[article.id] = content;

          if (kDebugMode) {
            print('‚úÖ PDF ${i + 1}/${articles.length} baixado: $titlePreview');
          }
        } catch (e) {
          if (kDebugMode) {
            print('‚ùå Erro ao baixar PDF ${i + 1}/${articles.length}: $e');
          }
          // Usa apenas o abstract como fallback
          pdfContents[article.id] =
              '${article.title}\n\nAutores: ${article.authors}\n\nResumo: ${article.summary}';
        }

        // Pequena pausa para n√£o sobrecarregar
        await Future.delayed(const Duration(milliseconds: 200));
      }

      // Agora processa todos os artigos de uma vez
      onProgress?.call('ü§ñ Analisando todos os artigos com IA...');

      for (int i = 0; i < articles.length; i++) {
        final article = articles[i];
        final titlePreview = article.title.length > 40
            ? '${article.title.substring(0, 40)}...'
            : article.title;

        onProgress?.call(
            'üîç Analisando artigo ${i + 1}/${articles.length}: $titlePreview');

        if (kDebugMode) {
          print(
              'üìñ Processando artigo ${i + 1}/${articles.length}: $titlePreview');
        }

        // Usa o conte√∫do do PDF baixado anteriormente
        final content = pdfContents[article.id] ??
            '${article.title}\n\nAutores: ${article.authors}\n\nResumo: ${article.summary}';

        try {
          // Gera resumo estruturado
          final summary = await generateSummary(content);

          final processed = '''
**ARTIGO:** ${article.title}
**AUTORES:** ${article.authors}
**DATA:** ${article.published.year}-${article.published.month.toString().padLeft(2, '0')}-${article.published.day.toString().padLeft(2, '0')}
**CATEGORIAS:** ${article.categories.join(', ')}
**LINK:** ${article.link}

$summary

---
''';
          processedArticles.add(processed);
          successCount++;
        } catch (e) {
          if (kDebugMode) {
            print('‚ùå Erro ao processar artigo: $e');
          }
          final processed = '''
**ARTIGO:** ${article.title}
**ERRO:** N√£o foi poss√≠vel processar este artigo completamente.
**RESUMO B√ÅSICO:** ${article.summary}

---
''';
          processedArticles.add(processed);
        }

        // Pausa pequena entre processamentos para n√£o sobrecarregar
        if (i < articles.length - 1) {
          await Future.delayed(const Duration(milliseconds: 500));
        }
      }

      onProgress?.call(
          '‚úÖ Processamento conclu√≠do: $successCount/${articles.length} artigos processados com sucesso');
      if (kDebugMode) {
        print(
            '‚úÖ Processamento conclu√≠do: $successCount/${articles.length} artigos processados com sucesso');
      }

      // Gera estado da arte final
      onProgress?.call('üß† Gerando estado da arte integrado...');
      if (kDebugMode) {
        print('üß† Gerando estado da arte integrado...');
      }
      final stateOfArt = await generateStateOfArt(processedArticles, topic);

      // Adiciona estat√≠sticas
      onProgress?.call('üìä Finalizando relat√≥rio...');
      final ramGB = await getSystemRAM();
      final hasGPU = await hasAICapableGPU();
      final modelUsed = await getRecommendedModel(ramGB);

      final header = '''
# üéì ESTADO DA ARTE AUTOMATIZADO: $topic

**üìä Estat√≠sticas da An√°lise:**
- **Total de artigos analisados:** ${articles.length}
- **Artigos processados com sucesso:** $successCount
- **Per√≠odo coberto:** ${articles.isNotEmpty ? '${articles.last.published.year} - ${articles.first.published.year}' : 'N/A'}
- **Gerado em:** ${DateTime.now().toString().split('.')[0]}
- **Sistema de IA:** Ollama + $modelUsed
- **Hardware:** ${ramGB}GB RAM${hasGPU ? ' + GPU dedicada' : ' (apenas CPU)'}

---

''';

      return header + stateOfArt;
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Erro na gera√ß√£o do estado da arte: $e');
      }
      return '''
# ‚ùå ERRO NA GERA√á√ÉO DO ESTADO DA ARTE

Ocorreu um erro durante o processamento:
$e

Por favor, verifique se:
1. O Ollama est√° instalado e rodando
2. H√° conex√£o com internet para baixar os PDFs
3. O modelo de IA est√° dispon√≠vel

Tente novamente ou use as funcionalidades b√°sicas de exporta√ß√£o.
''';
    }
  }
}
